---
title: "Additional Course Materials"
author: "Dillon Niederhut"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
- pdf_document
- slidy_presentation
---

```{r, echo=FALSE}
knitr::opts_knit$set(root.dir = '../')
```

## Introduction

The following are materials that do not fit into the course as currently taught, but that may be useful for students later on.

# Data does not need to be in the local filesystem

## R has an interface to curl called RCurl

```{r}
#install.packages('RCurl')
library(RCurl)
#install.packages("XML")
library(XML)
```

## you can use this to access remote data

you may just want to read text lines from a webpage

```{r}
RJ <- readLines("http://shakespeare.mit.edu/romeo_juliet/full.html")  
RJ[1:25]
```

and use the kinds of string manipulation we learned yesterday to retrieve the first lines of an act or a scene

```{r}
RJ[grep("<h3>", RJ, perl=T)]
RJ[grep("<h3>", RJ, perl=TRUE)]
```

or maybe pull information out of an RSS feed

```{r, eval=FALSE}
link <- "http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml"
page <- getURL(url = link)
xmlParse(file = page)
```

## R also has libraries for pulling and parsing web pages

```{r}
link<-"http://clerk.house.gov/evs/2014/ROLL_000.asp"
readHTMLTable(doc=link, header=T, which=1, stringsAsFactors=F)[1:10, ]
```

# Connecting to a database

why read from a database? they use less memory, are faster, create their own backups, and offer optimized querying/joining

databases generally come in two flavors, relational and non-relational, which has to do with how important schemas are (and is a bit beyond the scope of an R intro)

two popular relational databases are SQL (or one of its many flavors)

```{r, eval=FALSE}
#are there websites that allow you to connect to test servers?
install.packages("RMySQL")
library(RMySQL)
con <- dbConnect(MySQL(),
         user="", password="",
         dbname="", host="localhost")
data <- fetch(dbSendQuery(con, "select * from table"), n=10)
con.exit(dbDisconnect(con))
```

and postgres

```{r, eval=FALSE}
install.packages("RPostgreSQL")
library(RPostgreSQL)
con <- dbConnect(dbDriver("PostgreSQL"),
                 dbname="", 
                 host="localhost",
                 port=1234, 
                 user="", 
                 password="")
data <- dbReadTable(con, c("column1","column2"))
dbDisconnect(con)
```

a popular non-relational database is MongoDB

```{r, eval=FALSE}
install.packages("rmongodb")
library(rmongodb)
con <- mongo.create(host = localhost, 
                      name = "", 
                      username = "", 
                      password = "", 
                      db = "admin")
if(mongo.is.connected(con) == TRUE) {
  data <- mongo.find.all(con, "collection", list("city" = list( "$exists" = "true")))
}
mongo.destroy(con)
```

one quirk about mongo is that your connection always authenticates to the authentication database, not the database you are querying - this db is usually called 'admin'

# Data tidying with plyr

## enter plyr

- *plyr* is the go-to package for all your splitting-applying-combining needs
- Among its many benefits (above base R capabilities):
a) Don't have to worry about different name, argument, or output consistencies
b) Easily parallelized 
c) Input from, and output to, data frames, matricies, and lists
d) Progress bars for lengthy computation
e) Informative error messages

## group-wise operations/plyr/selecting functions

- Two essential questions:
    1. What is the class of your input object?
    2. What is the class of your desired output object?
- If you want to split a **d**ata frame, and return results as a **d**ata frame, you use **dd**ply
- If you want to split a **d**ata frame, and return results as a **l**ist, you use **dl**ply
- If you want to split a **l**ist, and return results as a **d**ata frame, you use **ld**ply


```{r, eval=FALSE}
# plyr package
mydata <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
# Consider the case where we want to calculate descriptive statistics across admits and not-admits
# from the dataset and return them as a data.frame
ddata <- ddply(mydata, c("admit"), summarize, 
                gpa.over3 = length(gpa[gpa>=3]),
                gpa.over3.5 = length(gpa[gpa>=3.5]),
                gpa.over3per = length(gpa[gpa>=3])/length(gpa),
                gpa.over3.5per = length(gpa[gpa>=3.5])/length(gpa))
)
```

# Group-wise Operations/plyr/functions

- plyr can accomodate any user-defined function, but it also comes with some pre-defined functions that assist with the most common split-apply-combine tasks
- We've already seen **summarize**, which creates user-specified vectors and combines them into a data.frame.  Here are some other helpful functions:

**transform**: applies a function to a data.frame and adds new vectors (columns) to it

# add a column containing the average gre score of students

```{r, eval=FALSE}

mydata <- ddply(mydata, c("admit"), transform, 
                gre.ave=mean(x=gre, na.rm=T),
                gre.sd = sd(x=gre, na.rm=T))
head(mydata)
unique(mydata$gre.ave)
)
```

> side note: note that **transform** can't do transformations that involve the results of *other* transformations from the same call

Another very useful function is **arrange**, which orders a data frame on the basis of column contents

```{r, eval=FALSE}
# Another very useful function is arrange, which orders a data frame on the basis of column contents
# arrange by "rank"
mydata.rank <- plyr::arrange(mydata, rank)
# arrange by "rank", descending
mydata.rank <- plyr::arrange(mydata, desc(rank))
# arrange by "rank", then "gre", then "gpa
mydata.comb <- plyr::arrange(mydata, rank, desc(gre), desc(gpa))
head(mydata.comb)
```
